{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pydot\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#-----------------------------------------import and encoding of data so it can be used in randomForest Model-------------------------------------\n",
    "#dataset import\n",
    "colnames=['e/p','cap-shape', 'cap-surface', 'cap-color', 'bruises?', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color','ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat'] \n",
    "dataset = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\", names=colnames, header=0)\n",
    "\n",
    "#oneHOtEncoding\n",
    "labels = colnames\n",
    "categorical_data = dataset[labels]\n",
    "ohe = OneHotEncoder(categories='auto')\n",
    "feature_arr = ohe.fit_transform(categorical_data).toarray()\n",
    "ohe_labels = ohe.get_feature_names_out(labels)\n",
    "features = pd.DataFrame(feature_arr,columns=ohe_labels)\n",
    "#print(features)\n",
    "\n",
    "#-------------------------------------------------implementation of random forest AI model------------------------------------------------\n",
    "#preparing datasets\n",
    "x= features.iloc[:, -117:].values\n",
    "Y=features.iloc[:, :-117].values\n",
    "\n",
    "x_train,x_test, Y_train,Y_test = train_test_split(x, Y, test_size=0.3)\n",
    "\n",
    "\n",
    "#creating random forest regressor object\n",
    "param_grid= {\n",
    "    'n_estimators': np.array(range(70,120)),\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "regressor = RandomForestRegressor(random_state = 42)# scores are better with 100 estimators\n",
    "# we use grid_search to find the best parameters for regressor\n",
    "grid_search = GridSearchCV(regressor, param_grid=param_grid, cv=10, scoring='f1_macro', n_jobs=4)\n",
    "#print(regressor.get_params())#-->best n_estimators is 100\n",
    "\n",
    "regressor.fit(x_train, Y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "\n",
    "#---------------------------------test and values of errors of model---------------------------------------------------------------------------------\n",
    "#we do not use mape because it is problematic for datasets whose scales do not have a meaningful 0 or for intermittent demand datasets, where y_t=0 occurs frequently.\n",
    "#instead we use MASE: mean  absolut error\n",
    "#accuracy is usually not measured in regression so we only compute error values\n",
    "\n",
    "df=pd.DataFrame({'Actual':Y_test.flatten(), 'Predicted':y_pred.flatten()})\n",
    "#print(df)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))\n",
    "\n",
    "errors = abs(y_pred - Y_test)\n",
    "print('Mean Absolute Error: ', np.mean(errors), 'degrees.')\n",
    "\n",
    "\n",
    "trainScore = regressor.score(x_train, Y_train)\n",
    "print('Train Score: %.15f MSE (%.15f RMSE)' % (trainScore, np.sqrt(trainScore)))\n",
    "\n",
    "testScore = regressor.score(x_test, Y_test)\n",
    "print('test Score: %.15f MSE (%.15f RMSE)' % (testScore, np.sqrt(testScore)))\n",
    "\n",
    "\n",
    "#confusion matrix: ------------------------- TODO-----------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------------------graph to display performance-------------------------------------------------------------\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(5, 7))\n",
    "\n",
    "\n",
    "ax = sns.distplot(Y, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(y_pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax)\n",
    "\n",
    "\n",
    "plt.title('Actual vs Fitted Values')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86c3ae0d4867be8e64b1697bd151ae3cbb6ef27ca114925be34996514974870a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
